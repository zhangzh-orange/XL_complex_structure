{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2580191",
   "metadata": {},
   "source": [
    "# XL-MoLPC: Structure Assembly Pipeline for Protein Complexes\n",
    "\n",
    "This notebook demonstrates a complete pipeline for assembling protein complexes\n",
    "from interaction data, AlphaFold predictions, and crosslinking constraints.\n",
    "\n",
    "The workflow includes:\n",
    "\n",
    "1. Protein–protein interaction (PPI) network construction\n",
    "2. Manual curation of protein identifiers\n",
    "3. Network and sequence preparation\n",
    "4. Crosslink preprocessing\n",
    "5. AlphaFold structure rewriting and scoring\n",
    "6. Dimer extraction and selection\n",
    "7. Monte Carlo Tree Search (MCTS)–based complex assembly\n",
    "\n",
    "This notebook is intended as a **reproducible tutorial and presentation**\n",
    "of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27135c",
   "metadata": {},
   "source": [
    "## Global Configuration and File Paths\n",
    "\n",
    "This section defines all global paths used throughout the pipeline,\n",
    "including input data, intermediate files, AlphaFold predictions,\n",
    "and final outputs.\n",
    "\n",
    "Adjust `BASE_DIR` to point to your project directory before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project root directory\n",
    "BASE_DIR = r\"N:\\08_NK_structure_prediction\\data\\COPI_complex\"\n",
    "\n",
    "# Input files\n",
    "USEQS_CSV = f\"{BASE_DIR}/assembled_complex/useqs.csv\"\n",
    "RESIDUE_PAIR_CSV = (\n",
    "    f\"{BASE_DIR}/heklopit_pl3017_frd1ppi_sc151_fdr1rp_COPI_cleaned.csv\"\n",
    ")\n",
    "FASTA_PATH = f\"{BASE_DIR}/assembled_complex/COPI.fasta\"\n",
    "\n",
    "# Intermediate files\n",
    "UCROSSLINKS_CSV = f\"{BASE_DIR}/assembled_complex/ucrosslinks.csv\"\n",
    "CHAINS_CSV = f\"{BASE_DIR}/assembled_complex/chains.csv\"\n",
    "\n",
    "# AlphaFold prediction directory\n",
    "AF_PRED_DIR = f\"{BASE_DIR}/afx_pred\"\n",
    "\n",
    "# Files for assembly\n",
    "NETWORK_CSV = f\"{BASE_DIR}/assembled_complex/network.csv\"\n",
    "PAIRS_DIR = f\"{BASE_DIR}/assembled_complex/pairs\"\n",
    "\n",
    "# Output directories\n",
    "REWRITED_PDB_DIR = f\"{BASE_DIR}/assembled_complex/rewrited_pdbs\"\n",
    "OUTPUT_DIR = f\"{BASE_DIR}/assembled_complex/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce8426",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "This pipeline relies on custom modules for preprocessing, network analysis,\n",
    "structure rewriting, and MCTS-based assembly.\n",
    "\n",
    "Please ensure that all required packages and local modules are available\n",
    "in your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from complex_assembly.rewrite_af_files import *\n",
    "from complex_assembly.mcts import main\n",
    "from preprocess.crosslink_prepare import *\n",
    "from preprocess.network_prepare import build_network_and_useqs\n",
    "from network.interact_map import *\n",
    "import complex_assembly.mcts as mcts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cc796",
   "metadata": {},
   "source": [
    "## Manual Preparation of `chains.csv`\n",
    "\n",
    "The `chains.csv` file defines the mapping between proteins and chain IDs\n",
    "used in structure assembly.\n",
    "\n",
    "Example format (tab-separated or CSV with consistent delimiter):\n",
    "\n",
    "| Entry | Gene | Chain |\n",
    "|-------|-------|-------|\n",
    "| Q8WUH2 | TGFBRAP1 | A |\n",
    "| Q9H270 | VPS11 | B |\n",
    "| ... | ... | ... |\n",
    "\n",
    "**Requirements:**\n",
    "- Column names must be exactly: `Entry`, `Gene`, `Chain`\n",
    "- Each chain ID should be a single uppercase letter (A, B, C, …)\n",
    "- Each gene should appear only once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3002db2",
   "metadata": {},
   "source": [
    "## Manual Preparation of FASTA File\n",
    "\n",
    "The FASTA file must contain protein sequences corresponding to the `Gene`\n",
    "column in `chains.csv`.\n",
    "\n",
    "Each FASTA header **must include a `GN=` field**, for example:\n",
    "\n",
    "&gt;sp|Q8WUH2|TGFA1_HUMAN Transforming growth factor-beta receptor-associated protein 1 OS=Homo sapiens OX=9606 GN=TGFBRAP1 PE=1 SV=1\n",
    "MMSIKAFTLVSAVERELLMGDKERVNIECVECCGRDLYVGTNDCFVYHFLLEERPVPAGPATFTATKQLQRHLGFKKPVN...\n",
    "\n",
    "**Important notes:**\n",
    "- The gene name after `GN=` must exactly match the `Gene` column in `chains.csv`\n",
    "- Only one sequence per gene is required\n",
    "- Standard UniProt FASTA format is supported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066764a",
   "metadata": {},
   "source": [
    "## Manual Curation of Protein Identifiers\n",
    "\n",
    "Some interaction datasets contain merged or ambiguous protein names\n",
    "(e.g. `COPB2; COPB2`).\n",
    "\n",
    "We manually define a mapping to clean these node names before downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load interaction data and build the PPI network\n",
    "df = load_interaction_data(RESIDUE_PAIR_CSV)\n",
    "G = build_ppi_network(df)\n",
    "\n",
    "# Identify nodes that require manual cleanup\n",
    "dirty_nodes = [n for n in G.nodes() if \";\" in str(n)]\n",
    "print(\"Nodes needing cleanup:\", dirty_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b98d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define mappings for cleaning node names\n",
    "manual_map = {\n",
    "    'COPB2; COPB2':'COPB2', \n",
    "    'ASS1; ARCN1':'ARCN1', \n",
    "    'COPB1; COPB1':'COPB1', \n",
    "    'COPA; COPA':'COPA', \n",
    "    'COPB1; COPB1; COPB1; COPB1':'COPB1', \n",
    "    'ARF4; ARF6; ARF1; ARF5':'ARF1', \n",
    "    'COPG2; COPG1':'COPG1', \n",
    "    'COPZ1; COPZ1':'COPZ1'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84616cb",
   "metadata": {},
   "source": [
    "## Define Target Protein Set\n",
    "\n",
    "Here we specify the list of proteins that define the complex of interest.\n",
    "Only interactions among these proteins will be considered for assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 手动定义需要分析的复合体 ======\n",
    "protein_list = [\"COPB1\",\n",
    "                \"COPZ1\",\n",
    "                \"COPG1\",\n",
    "                \"ARCN1\",\n",
    "                \"COPE\",\n",
    "                \"COPB2\",\n",
    "                \"COPA\",\n",
    "                \"ARF1\",\n",
    "                \"ARFGAP2\",\n",
    "                \"ARFGAP3\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95cfbb",
   "metadata": {},
   "source": [
    "## Cleaned PPI Network Visualization and Complex Enumeration\n",
    "\n",
    "After cleaning node names, we:\n",
    "\n",
    "1. Visualize the PPI network\n",
    "2. Rewrite the original interaction file using cleaned identifiers\n",
    "3. Enumerate valid dimers and trimers present in the network\n",
    "4. Export results for downstream processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9907db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply node name cleanup\n",
    "G = clean_node_names(G, manual_map)\n",
    "\n",
    "# Visualize the cleaned PPI network\n",
    "plot_ppi_network(G, \"COPI Complex PPI Network (Cleaned Names)\")\n",
    "\n",
    "# Rewrite the original residue-pair file using cleaned names\n",
    "clean_residue_pair_file(RESIDUE_PAIR_CSV, manual_map)\n",
    "\n",
    "\n",
    "# Analyze binary and ternary complexes in the PPI network\n",
    "dimer_in_ppi, trimer_in_ppi = analyze_complexes(G, protein_list)\n",
    "\n",
    "# Save results\n",
    "dimer_path = os.path.join(OUTPUT_DIR,\"dimers.csv\")\n",
    "trimer_path = os.path.join(OUTPUT_DIR,\"trimers.csv\")\n",
    "\n",
    "df_binary_ppi = pd.DataFrame(set(dimer_in_ppi), columns=[\"p1\", \"p2\"])\n",
    "df_binary_ppi.to_csv(dimer_path, index=False)\n",
    "\n",
    "df_triplet_ppi = pd.DataFrame(set(trimer_in_ppi), columns=[\"p1\", \"p2\", \"p3\"])\n",
    "df_triplet_ppi.to_csv(trimer_path, index=False)\n",
    "\n",
    "print(f\"Total triplets: {len(list(combinations(protein_list, 3)))}\")\n",
    "print(f\"Triplets found in PPI: {len(trimer_in_ppi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build assembly network and unified sequence table\n",
    "network_df, useq_df = build_network_and_useqs(\n",
    "    binary_csv=dimer_path,\n",
    "    chains_csv=CHAINS_CSV,\n",
    "    fasta_file=FASTA_PATH,\n",
    "    network_out=NETWORK_CSV,\n",
    "    useqs_out=USEQS_CSV\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c1346",
   "metadata": {},
   "source": [
    "## Step 1 — Prepare Crosslink Constraints\n",
    "\n",
    "Crosslink data are mapped onto unified sequences to generate\n",
    "a standardized crosslink table (`ucrosslinks.csv`).\n",
    "\n",
    "This file is later used as a spatial constraint during MCTS assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "useq_df = pd.read_csv(USEQS_CSV)\n",
    "residue_pair_df = pd.read_csv(RESIDUE_PAIR_CSV)\n",
    "\n",
    "ucrosslinks = crosslink_prepare(useq_df, residue_pair_df)\n",
    "ucrosslinks.to_csv(UCROSSLINKS_CSV, index=False)\n",
    "\n",
    "print(\"✔ ucrosslinks written to:\", UCROSSLINKS_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785c88c",
   "metadata": {},
   "source": [
    "## Step 2 — Rewrite AlphaFold PDB/CIF and Score Files\n",
    "\n",
    "AlphaFold predictions are rewritten to ensure:\n",
    "\n",
    "- Consistent chain naming\n",
    "- Compatibility with downstream assembly steps\n",
    "\n",
    "Note: If this step terminates early, re-running the cell will automatically\n",
    "resume from the last completed structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_af_cif_structure(\n",
    "    af_pred_folder=AF_PRED_DIR,\n",
    "    chains_df_path=CHAINS_CSV,\n",
    "    output_folder=REWRITED_PDB_DIR,\n",
    ")\n",
    "\n",
    "print(\"✔ AF PDB rewritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_af_score_file(\n",
    "    af_pred_folder=AF_PRED_DIR,\n",
    "    chains_df_path=CHAINS_CSV,\n",
    "    output_folder=REWRITED_PDB_DIR,\n",
    ")\n",
    "\n",
    "print(\"✔ score rewritten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d0601",
   "metadata": {},
   "source": [
    "## Step 3 — Split Trimer Predictions into Dimers\n",
    "\n",
    "Trimer AlphaFold predictions are decomposed into all possible dimer pairs.\n",
    "\n",
    "These dimers form the candidate structural building blocks\n",
    "for complex assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d20267",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_trimer_to_dimers(\n",
    "    REWRITED_PDB_DIR,\n",
    "    PAIRS_DIR\n",
    ")\n",
    "\n",
    "print(\"✔ Trimer split to dimers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ebf19",
   "metadata": {},
   "source": [
    "## Step 4 — Select Central Dimer Structures\n",
    "\n",
    "For each protein pair, the most central or representative dimer\n",
    "is selected based on structural criteria.\n",
    "\n",
    "This reduces redundancy and improves assembly efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3de6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_most_central_pdb(PAIRS_DIR)\n",
    "\n",
    "print(\"✔ Central dimers selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c9c1d",
   "metadata": {},
   "source": [
    "## Step 5 — Monte Carlo Tree Search (MCTS) Assembly\n",
    "\n",
    "Finally, we assemble the full protein complex using an MCTS algorithm,\n",
    "guided by:\n",
    "\n",
    "- Network topology\n",
    "- Structural compatibility\n",
    "- Crosslinking constraints\n",
    "\n",
    "The final assembled structures and logs are written to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    network=NETWORK_CSV,\n",
    "    pairdir=PAIRS_DIR,\n",
    "    useqs=USEQS_CSV,\n",
    "    ucrosslinks=UCROSSLINKS_CSV,\n",
    "    outdir=OUTPUT_DIR,\n",
    ")\n",
    "\n",
    "mcts.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c05c9d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides an end-to-end demonstration of the\n",
    "protein complex assembly pipeline, from interaction data\n",
    "to final structural models.\n",
    "\n",
    "The modular design allows individual steps to be adapted\n",
    "or replaced depending on experimental input and biological context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xl_complex_structure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
